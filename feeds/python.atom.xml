<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Longwen's Blog - Python</title><link href="https://oulongwen.github.io/" rel="alternate"></link><link href="https://oulongwen.github.io/feeds/python.atom.xml" rel="self"></link><id>https://oulongwen.github.io/</id><updated>2017-02-08T00:00:00-05:00</updated><entry><title>Crawling and scraping Google Scholar with Scrapy</title><link href="https://oulongwen.github.io/crawl-google-cholar.html" rel="alternate"></link><published>2017-02-08T00:00:00-05:00</published><updated>2017-02-08T00:00:00-05:00</updated><author><name>Longwen Ou</name></author><id>tag:oulongwen.github.io,2017-02-08:/crawl-google-cholar.html</id><summary type="html">&lt;p&gt;Introduction to web crawling and scraping with Scrapy&lt;/p&gt;</summary><content type="html">&lt;p&gt;I am learning web crawling and scraping since it is useful when you want to extract data from websites when no API is available. Since I use python, I searched for some good tools for this task. Eventually I decided to go with &lt;a href="https://scrapy.org"&gt;&lt;code&gt;Scrapy&lt;/code&gt;&lt;/a&gt; due to its ease to use and capability of both web crawling and scraping. In this post I show the process of crawling and scraping &lt;em&gt;Google Scholar&lt;/em&gt; with &lt;code&gt;Scrapy&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The purpose of this project is to download information on all publications of an author as well as information on the publications which cited the author's work. The source code is available on &lt;a href="https://github.com/oulongwen/google-scholar-crawler"&gt;my github&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;Installing Scrapy&lt;/h3&gt;
&lt;p&gt;Installing &lt;code&gt;Scrapy&lt;/code&gt; is pretty straightforward. You can install &lt;code&gt;Scrapy&lt;/code&gt; with &lt;code&gt;pip&lt;/code&gt;: &lt;code&gt;pip install Scrapy&lt;/code&gt;. However, this is not the recommended way of installing &lt;code&gt;Scrapy&lt;/code&gt;. For web development tools such as &lt;code&gt;Scrapy&lt;/code&gt;, &lt;code&gt;pelican&lt;/code&gt;, and &lt;code&gt;Djaon&lt;/code&gt;, the best practice is to install them in an "isolated" environment becuase your project is going to rely on this particular version of package. A good introduction about virtual environment in python can be found &lt;a href="http://docs.python-guide.org/en/latest/dev/virtualenvs/"&gt;here&lt;/a&gt;. If you are using python3, creating a virtual environment is pretty simple:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ python3 -m venv scrapyvenv
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Here &lt;code&gt;scrapyvenv&lt;/code&gt; is just the name of your virtual environment and you can name it whatever you want. Now that the virtual environment is created, we can activate the virtual environment:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ &lt;span class="nb"&gt;source&lt;/span&gt; scrapyvenv/bin/activate
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now our virtual environment should be ready. You can check whether your virtual environment is already activated by the following command:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ which python
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;If your virtual environment is activated, you will see something like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ path-to-venv/scrapyvenv/bin/python
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now that our virtual environment is ready, we can install &lt;code&gt;Scrapy&lt;/code&gt; with &lt;code&gt;pip&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ pip install Scrapy
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;Web scraping with Scrapy&lt;/h3&gt;
&lt;h4&gt;Defining spiders&lt;/h4&gt;
&lt;p&gt;In order to start scrapying, a Scrapy project must be first set up. Here I named my project "scholar":&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ scrapy start project scholar
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The above command creates a &lt;code&gt;scholar&lt;/code&gt; directory together with several sub-directories and files. The most important directory is the &lt;code&gt;spiders&lt;/code&gt; folder located at &lt;code&gt;.../scholar/scholar/spiders&lt;/code&gt;. This folder contains the python files where we define our spiders for web crawling. We define each spider as a class, where we also define its name and the url to start crawling. The name of a spider is important because this is how &lt;code&gt;Scrapy&lt;/code&gt; identifies a spider. Another important component of a &lt;em&gt;spider&lt;/em&gt; class is the &lt;code&gt;parse&lt;/code&gt; method which will be called to handle the response downloaded for each request. A &lt;code&gt;parse&lt;/code&gt; method has two basic functions: 1) to extract data, and 2) to yield another request with a specified &lt;code&gt;parse&lt;/code&gt; method to handle this request. My &lt;code&gt;cite_spider.py&lt;/code&gt; file looks like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;scrapy&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;scholar.items&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;ScholarItem&lt;/span&gt;


&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;CiteSpider&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;scrapy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Spider&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="n"&gt;name&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;citation&amp;quot;&lt;/span&gt;
    &lt;span class="n"&gt;page_size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;20&lt;/span&gt;
    &lt;span class="n"&gt;start&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
    &lt;span class="c1"&gt;# urls = &amp;#39;https://scholar.google.com/citations?user=nbPXtEUAAAAJ&amp;amp;hl=en&amp;#39;&lt;/span&gt;
    &lt;span class="n"&gt;urls&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;https://scholar.google.com/citations?user=EXATcMAAAAAJ&amp;amp;hl=en&amp;#39;&lt;/span&gt;
    &lt;span class="n"&gt;start_urls&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;urls&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;&amp;amp;cstart={}&amp;amp;pagesize={}&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;start&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;page_size&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;parse&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;response&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;response&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;css&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;td.gsc_a_t&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;extract_first&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="ow"&gt;is&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
            &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;paper&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;response&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;css&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;td.gsc_a_t&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
                &lt;span class="n"&gt;paper_title&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;paper&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;css&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;a::text&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;extract_first&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
                &lt;span class="n"&gt;paper_authors&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;paper&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;css&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;div.gs_gray::text&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;extract_first&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

                &lt;span class="n"&gt;item&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ScholarItem&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
                &lt;span class="n"&gt;item&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;title&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;paper_title&lt;/span&gt;
                &lt;span class="n"&gt;item&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;authors&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;paper_authors&lt;/span&gt;
                &lt;span class="k"&gt;yield&lt;/span&gt; &lt;span class="n"&gt;item&lt;/span&gt;

            &lt;span class="n"&gt;CiteSpider&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;start&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;CiteSpider&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;page_size&lt;/span&gt;
            &lt;span class="n"&gt;next_page&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;CiteSpider&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;start_urls&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s1"&gt;&amp;#39;&amp;amp;cstart={}&amp;amp;pagesize={}&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;CiteSpider&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;start&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;CiteSpider&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;page_size&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
            &lt;span class="k"&gt;yield&lt;/span&gt; &lt;span class="n"&gt;scrapy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Request&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;next_page&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;callback&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;parse&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

            &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;cite&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;response&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;css&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;td.gsc_a_c a::attr(href)&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;extract&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
                &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;cite&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                    &lt;span class="k"&gt;yield&lt;/span&gt; &lt;span class="n"&gt;scrapy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Request&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;cite&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;callback&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;parse2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

    &lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;parse2&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;response&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;

        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;paper&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;response&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;css&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;div.gs_ri&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;

            &lt;span class="n"&gt;item&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ScholarItem&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
            &lt;span class="n"&gt;item&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;title&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;paper&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;css&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;h3.gs_rt a::text&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;extract_first&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
            &lt;span class="n"&gt;item&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;authors&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;paper&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;css&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;div.gs_a::text&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;extract_first&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
            &lt;span class="k"&gt;yield&lt;/span&gt; &lt;span class="n"&gt;item&lt;/span&gt;

            &lt;span class="n"&gt;next_page&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;response&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;xpath&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s1"&gt;&amp;#39;//span[@class=&amp;quot;gs_ico gs_ico_nav_next&amp;quot;]/../@href&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;extract_first&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
            &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;next_page&lt;/span&gt; &lt;span class="ow"&gt;is&lt;/span&gt; &lt;span class="ow"&gt;not&lt;/span&gt; &lt;span class="bp"&gt;None&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
                &lt;span class="n"&gt;next_page&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;response&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;urljoin&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;next_page&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
                &lt;span class="k"&gt;yield&lt;/span&gt; &lt;span class="n"&gt;scrapy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Request&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;next_page&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;callback&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;self&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;parse2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Here I defined two parse functions, because there are two types of web pages I need to handle. Each type of web page has different structures from the other. In other words, our desired content on each type of website is in different html tags. For instance, the first type of web pages to handle is the pages showing the list of publications of a particular author. It looks like this:&lt;/p&gt;
&lt;p&gt;&lt;img src='/images/author.png' width=100%/&gt;&lt;/p&gt;
&lt;p&gt;The information in this page that we are interested in is the title of the publications and other information such as authors, journal title, year of publication, etc. In order to extract the desired information, we need to identify the html tags that contain these information. It is convenient with chrome. Just right click the information you are interested and click &lt;em&gt;"Inspect"&lt;/em&gt;, we can inspect the source code that contains the information. Here the title is under a &lt;code&gt;&amp;lt;td&amp;gt;&lt;/code&gt; tag with &lt;code&gt;class=gsc_a_t&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The second type of pages result from clicking the link of the number indicating the number of citations of each publication. These links direct to pages showing a list of publications that the original publication is cited by. The page is shown below. These pages have very different structures as the first type of pages. Therefore we need two &lt;code&gt;parse&lt;/code&gt; methods, each handling one type of the pages.&lt;/p&gt;
&lt;p&gt;&lt;img src='/images/cite.png' width=100%/&gt;&lt;/p&gt;
&lt;h4&gt;Writing &lt;em&gt;items.py&lt;/em&gt; file&lt;/h4&gt;
&lt;p&gt;&lt;code&gt;Scrapy&lt;/code&gt; usually returns extracted data as dictionaries. However, it is not recommened to define the dictionary to return in the same file where spiders are defined. The reason is that if a typo is made when defining the dictionary keys, a completely different dictionary would be created without raising any errors. Hence &lt;code&gt;Scrapy&lt;/code&gt; allows defining the dictionary keys in the &lt;code&gt;items.py&lt;/code&gt; file. After importing the items.py file in the spider file, only dictionaries with the acceptable keys (i.e., keys defined in the &lt;code&gt;items.py&lt;/code&gt; file) can be returned. If the user attempted to write a dictionary with a key not defined in the &lt;code&gt;items.py&lt;/code&gt; file, an error would be raised. This is good practice for preventing unintentional mistakes. In this project, two fields are needed to store the title and other information for each paper respectively. The &lt;em&gt;items.py&lt;/em&gt; files looks like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;scrapy&lt;/span&gt;


&lt;span class="k"&gt;class&lt;/span&gt; &lt;span class="nc"&gt;ScholarItem&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;scrapy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Item&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="c1"&gt;# define the fields for your item here like:&lt;/span&gt;
    &lt;span class="c1"&gt;# name = scrapy.Field()&lt;/span&gt;
    &lt;span class="n"&gt;title&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;scrapy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Field&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
    &lt;span class="n"&gt;authors&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;scrapy&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Field&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now that we have defined our spider, we can start crawling using the following command:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;$ scrapy crawl citation -o papers.jl
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Here &lt;em&gt;"citation"&lt;/em&gt; is the name of the spider, as defined in the &lt;code&gt;cite_spider.py&lt;/code&gt; file. The &lt;code&gt;-o&lt;/code&gt; flag specifies the output file storing the extracted data. Scrapy supports several output file format including &lt;code&gt;JSON&lt;/code&gt;, &lt;code&gt;JSON lines&lt;/code&gt;, &lt;code&gt;CSV&lt;/code&gt;, and &lt;code&gt;XML&lt;/code&gt;. Here I store the extracted data in &lt;code&gt;JSON line&lt;/code&gt; format. After the spider is successfully run, the specified output file will be created with all the extracted data.&lt;/p&gt;
&lt;p&gt;Again the source code can be found on &lt;a href="https://github.com/oulongwen/google-scholar-crawler"&gt;my github&lt;/a&gt;.&lt;/p&gt;</content><category term="Web scraping"></category><category term="Python"></category><category term="Scrapy"></category></entry><entry><title>Setting up python for macOS</title><link href="https://oulongwen.github.io/setting-up-python-for-macos.html" rel="alternate"></link><published>2017-01-16T23:36:00-05:00</published><updated>2017-01-16T23:36:00-05:00</updated><author><name>Longwen Ou</name></author><id>tag:oulongwen.github.io,2017-01-16:/setting-up-python-for-macos.html</id><summary type="html">&lt;p&gt;An introduction to my python setup&lt;/p&gt;</summary><content type="html">&lt;p&gt;&lt;a href="https://atom.io/"&gt;Atom&lt;/a&gt; is a cross-platform text editor developed by &lt;a href="https://github.com/"&gt;GitHub&lt;/a&gt;. It is highly comtomizable with support for plug-ins. In this post we'll talk about setting up Atom for Python, Latex and web development.&lt;/p&gt;
&lt;h2&gt;Atom settings&lt;/h2&gt;
&lt;p&gt;My atom settings looks like this:&lt;/p&gt;
&lt;p&gt;&lt;img src='/images/atom_theme.jpg' width=70%/&gt;&lt;/p&gt;
&lt;p&gt;I use &lt;a href="https://atom.io/themes/atom-material-ui"&gt;atom-material-ui&lt;/a&gt; UI theme and the corresponding syntax theme &lt;a href="https://atom.io/themes/atom-material-syntax"&gt;atom-material-syntax&lt;/a&gt;. I also installed &lt;a href="https://atom.io/packages/file-icons"&gt;file-icons&lt;/a&gt; to assign beautiful file extension icons and colors.&lt;/p&gt;
&lt;h2&gt;Set up Atom for Python Programming&lt;/h2&gt;
&lt;p&gt;There are a number of packages for python programming.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://atom.io/packages/autocomplete-python"&gt;autocomplete-python&lt;/a&gt;: provides autocompletion for Python packages, variables, methods, and functions.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://atom.io/packages/linter"&gt;linter&lt;/a&gt;: a base linter provider. It provides a top-level API to other packages to visualize errors and other kind-of messages, easily.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://atom.io/packages/linter-flake8"&gt;linter-flake8&lt;/a&gt;: a flake8 provider for linter. It requires installation of &lt;a href="https://pypi.python.org/pypi/flake8"&gt;flake8&lt;/a&gt; python package.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://atom.io/packages/linter-pep8"&gt;linter-pep8&lt;/a&gt;: provides an interface to pep8. It requires installation of &lt;a href="https://pypi.python.org/pypi/pep8"&gt;pep8&lt;/a&gt; python package.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href="https://atom.io/packages/python-tools"&gt;python-tools&lt;/a&gt;: provides handy tools for developing Python code. It bring feature such as Goto Definition, Select String Contents, etc.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Now you'are ready to have some fun developing Python code with atom. Congrats :-)&lt;/p&gt;
&lt;p&gt;Python is a popular programming language. Python comes with macOS. However, it is not recommended
to use the system python for development.&lt;/p&gt;
&lt;h2&gt;Installing python on macOS&lt;/h2&gt;
&lt;p&gt;There are two ways of installing python on macOS. The first way is to install python from source.  &lt;/p&gt;</content><category term="atom"></category><category term="python"></category><category term="macOS"></category></entry></feed>